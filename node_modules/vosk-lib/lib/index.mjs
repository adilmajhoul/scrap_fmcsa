var z=Object.defineProperty;var m=(t,e)=>{for(var s in e)z(t,s,{get:e[s],enumerable:!0})};import{fileURLToPath as R}from"url";import x from"path";var P=()=>R(import.meta.url),w=()=>x.dirname(P()),i=w();var v={};m(v,{Model:()=>d,SpeakerModel:()=>u,libvosk:()=>r});import a from"path";import y from"ffi-napi";import n from"ref-napi";var T=n.types.void,_=n.refType(T),S=n.types.void,p=n.refType(S),M=n.types.void,o=n.refType(M);function U(){let t=a.resolve(i,"..",`bin-${process.platform}-${process.arch}`);return process.platform=="win32"?(process.env.Path=t+a.delimiter+process.env.Path,a.join(t,"libvosk.dll")):process.platform=="darwin"?a.join(t,"libvosk.dylib"):a.join(t,"libvosk.so")}var r=y.Library(U(),{vosk_set_log_level:["void",["int"]],vosk_model_new:[_,["string"]],vosk_model_free:["void",[_]],vosk_spk_model_new:[p,["string"]],vosk_spk_model_free:["void",[p]],vosk_recognizer_new:[o,[_,"float"]],vosk_recognizer_new_spk:[o,[_,"float",p]],vosk_recognizer_new_grm:[o,[_,"float","string"]],vosk_recognizer_free:["void",[o]],vosk_recognizer_set_max_alternatives:["void",[o,"int"]],vosk_recognizer_set_words:["void",[o,"bool"]],vosk_recognizer_set_partial_words:["void",[o,"bool"]],vosk_recognizer_set_spk_model:["void",[o,p]],vosk_recognizer_accept_waveform:["bool",[o,"pointer","int"]],vosk_recognizer_result:["string",[o]],vosk_recognizer_final_result:["string",[o]],vosk_recognizer_partial_result:["string",[o]],vosk_recognizer_reset:["void",[o]]}),d=class{constructor(e){this.handle=r.vosk_model_new(e)}free(){r.vosk_model_free(this.handle)}},u=class{constructor(e){this.handle=r.vosk_spk_model_new(e)}free(){r.vosk_spk_model_free(this.handle)}};var k={};m(k,{setLogLevel:()=>W});function W(t){r.vosk_set_log_level(t)}var g={};m(g,{Recognizer:()=>f});var f=class{constructor(e){let{model:s,sampleRate:l}=e;if(e.speakerModel&&e.grammar)throw new Error("grammar and speakerModel cannot be used together for now.");this.handle=e.speakerModel?r.vosk_recognizer_new_spk(s.handle,l,e.speakerModel.handle):e.grammar?r.vosk_recognizer_new_grm(s.handle,l,JSON.stringify(e.grammar)):r.vosk_recognizer_new(s.handle,l)}free(){r.vosk_recognizer_free(this.handle)}setMaxAlternatives(e){return r.vosk_recognizer_set_max_alternatives(this.handle,e),this}setWords(e){return r.vosk_recognizer_set_words(this.handle,e),this}setPartialWords(e){return r.vosk_recognizer_set_partial_words(this.handle,e),this}setSpkModel(e){return r.vosk_recognizer_set_spk_model(this.handle,e.handle),this}acceptWaveform(e){return r.vosk_recognizer_accept_waveform(this.handle,e,e.length)}acceptWaveformAsync(e){return new Promise((s,l)=>{r.vosk_recognizer_accept_waveform.async(this.handle,e,e.length,function(h,b){h?l(h):s(b)})})}resultString(){return r.vosk_recognizer_result(this.handle)}result(){return JSON.parse(r.vosk_recognizer_result(this.handle)||"null")}partialResult(){return JSON.parse(r.vosk_recognizer_partial_result(this.handle)||"null")}finalResult(){return JSON.parse(r.vosk_recognizer_final_result(this.handle)||"null")}reset(){return r.vosk_recognizer_reset(this.handle),this}};var $={...v,...k,...g};export{d as Model,f as Recognizer,u as SpeakerModel,$ as default,r as libvosk,W as setLogLevel};
